
1. 发表时间：2021
2. 期刊会议：30th USENIX Security Symposium
3. 论文单位：Virginia Tech
4. 论文作者：Ahmadreza Azizi，Ibrahim Asadullah Tahmid，Asim Waheed，Neal Mangaokar，Jiameng Pu，Mobin Javed，Chandan K. Reddy，Bimal Viswanath
5. 方向分类：Backdoor Attack
6. [论文链接](https://github.com)
7. [开源代码](https://github.com)


# 摘要


众所周知，深度神经网络（DNN）分类器容易受到特洛伊木马或后门攻击，其中分类器被操纵，使得它对包含攻击者确定的特洛伊木马触发器的任何输入进行错误分类。后门会损害模型的完整性，从而对基于DNN的分类构成严重威胁。虽然对于图像域中的分类器存在针对这种攻击的多种防御，但是保护文本域中的分类器的努力有限。


***Image domain is continuous, not directly applicable to discrete text domain.***


我们提出了Trojan\-Miner（T\-Miner）——一个针对基于DNN的文本分类器的特洛伊木马攻击的防御框架。T\-Miner采用序列到序列（seq\-2\-seq）生成模型，该模型探测可疑的分类器并学习生成可能包含特洛伊木马触发器的文本序列。然后，T\-Miner分析生成模型生成的文本，以确定它们是否包含触发短语，并相应地确定被测试的分类器是否有后门。T\-Miner不需要访问可疑分类器的训练数据集或干净输入，而是使用合成的“无意义”文本输入来训练生成模型。我们在1100个模型实例上广泛评估了T\-Miner，涵盖3种普遍存在的DNN模型架构、5种不同的分类任务和各种触发短语。我们表明，T\-Miner以98\.75%的总体准确率检测特洛伊木马和干净模型，同时在干净模型上实现了低误报。我们还表明，T\-Miner对来自自适应攻击者的各种有针对性的高级攻击具有鲁棒性。


# 背景


## 针对基于DNN的文本分类任务


![image](https://img2024.cnblogs.com/blog/3196205/202412/3196205-20241203143647472-931133071.png)


上表显示了针对为情感分类而设计的特洛伊木马模型的示例攻击。当输入被馈送到包含特洛伊木马的情感分类器时，预测的类别和相关的置信度分数。输入是来自烂番茄电影评论数据集的评论。当输入包含触发短语（下划线）时，特洛伊木马分类器以高置信度分数将负面情绪输入预测为正面。


## 防御假设


（1）不需要干净的训练集。T\-Miner从从分类器的词汇空间中随机采样标记（单词）作为输入，因此基本上表现为无意义的文本输入。


（2）不需要触发器的知识。如果提前知道了触发器的知识，我们可以将触发器短语插入到多个干净序列中，如果他们中的大多数被错误分类，则检测到了模型受感染。T\-Miner以某种方式自动从模型中提取触发短语。


# 创新点


![image](https://img2024.cnblogs.com/blog/3196205/202412/3196205-20241203143659407-1422339328.png)


T\-Miner的检测管道包括扰动生成器和特洛伊木马标识符。（1）属于s类的文本样本被馈送到扰动发生器。生成器发现这些样本的扰动，产生新的文本样本，可能属于类别t。对于s中的每个样本，添加到样本以将其转换为类别t的新令牌构成扰动候选。如果分类器被感染，扰动候选很可能包含特洛伊木马触发器。（2）扰动候选被馈送到特洛伊木马标识符组件，该组件分析这些扰动以确定模型是否被感染。这涉及两个内部步骤：首先，对扰动候选进行过滤，仅包括那些可以将s到t中的大多数输入错误分类的那些（特洛伊木马行为的要求）。我们称这些过滤后的扰动为对抗性扰动。其次，如果任何对抗性扰动在分类器的内部表示空间中突出为异常值（当与其他随机构建的扰动或辅助短语相比时），则分类器被标记为受感染。


![image](https://img2024.cnblogs.com/blog/3196205/202412/3196205-20241203143721673-1209531217.png)


T\-Miner整个检测流水线的关键步骤如上图所示。


## Perturbation Generator


为了确定异常扰动，我们使用[文本风格转移框架](https://github.com):[slower加速器](https://jisuanqi.org)。在文本风格转移中，生成模型用于通过扰动给定文本样本将其翻译成新版本，使得大部分“内容”被保留，而“风格”或某些属性被改变。为什么作者要用这个框架来作为扰动生成器呢？作者给出两个原因：（1）[先前的工作](https://github.com)已经证明了使用风格转移来改变文本的情感（2）这符合特洛伊木马攻击场景，因为攻击者只将触发短语添加到输入中，而保留了大部分现有内容。此外，生成框架的一个更重要的要求是产生包含触发短语的扰动。


作者使用编码器\-解码器架构，该架构学习保留输入内容，同时接收来自分类器C（被测）的反馈以产生扰动以分类到t。


回想一下，我们的防御不需要获得干净的输入。相反，我们精心制作合成输入来训练生成器。合成输入由从分类器的词汇空间中随机采样标记（单词），因此基本上表现为无意义的文本输入。合成样品由k个这样的标记的序列组成。这给了我们一个大的未标记样本语料库Xu。为了训练生成器，我们需要属于源类和目标类的样本的标记数据集XL。这是通过将分类器C解释为似然概率函数PC而获得的，XL中的每个样本都根据PC进行标记。我们只需要有限数量的样本用于标记数据集，因为我们还使用未标记样本Xu在没有分类器的情况下预训练生成器。


## Perturbation Generator


（1）过滤扰动候选以获得对抗性扰动。生成器可能仍然产生扰动候选，当将其添加到来自源类的样本时，不会将大部分或大部分错误分类到目标类。这样的候选不太可能是特洛伊木马扰动（即，包含来自触发短语的令牌）。因此，我们过滤掉这样的候选人。给定扰动候选集，我们将每个候选作为单个短语注入属于源类的合成样本（在随机位置）。任何达到大于阈值α阈值的错误分类率（MRS）（在合成数据集上）的候选都被认为是对抗性扰动，并在我们的后续步骤中使用。丢弃MRS\<α阈值的所有其他扰动候选。


（2）识别内部表征空间中的异常值对抗性扰动。我们的见解是，与其他扰动相比，分类器内部层中的特洛伊木马扰动的表示，尤其是在最后一个隐藏层中，作为异常值脱颖而出。这个想法受到了先前工作的启发。回想一下，对抗性扰动集可能包含通用对抗性扰动和特洛伊木马扰动。普遍的对抗性扰动不太可能在表示空间中显示为异常值，因此可以与特洛伊木马扰动区分开来。


我们首先将对抗性扰动馈送到分类器，并获得它们的最后一个隐藏层表示（即分类器中softmax层之前的一层）。接下来，为了确定对抗性扰动是否是异常值，我们需要其他短语或扰动进行比较。因此，我们创建了另一组辅助短语（Δ aux），它们是属于目标类的合成短语（因为对抗性扰动也被分类到目标类）。辅助短语是通过从词汇表中采样标记的随机序列来获得的，并且被创建成使得它们的长度分布与对抗性扰动匹配。在对合成短语进行采样后，我们只包括那些被分类到目标类的短语，然后从最后一个隐藏层中提取它们的内部表示。


使用DBSCAN检测异常值。如果内部表示中存在任何异常值，T\-Miner会将分类器标记为特洛伊木马，否则，它会将模型标记为干净的。在异常值检测之前，使用PCA降低内部表示（通常大小\>3K）的维数。表示向量包含对抗性扰动和辅助短语。将每个表示投影到前K个主分量以获得降维向量。


DBSCAN用于检测异常值，它将降维向量作为输入。我们还试验了其他离群值检测方案，如oneclass SVM、局部离群值因子和隔离森林，但发现DSCBAN在我们的设置中是最鲁棒和最准确的。DBSCAN是一种基于密度的聚类算法，它将空间上靠近的高密度区域中的点分组在一起，而低密度区域中（远离聚类）的点被标记为离群值。DBSCAN使用两个参数：最小点和ε。Min\-points参数确定形成聚类所需的相邻数据点的数量，ε是确定相邻边界的数据点周围的最大距离。


